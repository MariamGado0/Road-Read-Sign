{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "#from imgaug import augmenters as iaa\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.layers.core import Activation\n",
    "from keras.layers.core import Flatten\n",
    "from keras.layers.core import Dropout\n",
    "from keras.layers.core import Dense\n",
    "from keras import backend as K\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, MaxPooling2D, Dropout, Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readTrafficSigns(rootpath):\n",
    "    '''Reads traffic sign data for German Traffic Sign Recognition Benchmark.\n",
    "    Arguments: path to the traffic sign data, for example './GTSRB/Training'\n",
    "    Returns:   list of images, list of corresponding labels'''\n",
    "    images = [] # images\n",
    "    labels = [] # corresponding labels\n",
    "    # loop over all 42 classes\n",
    "    for c in range(0,43):\n",
    "        prefix = rootpath + '/' + format(c, '05d') + '/' # subdirectory for class\n",
    "        gtFile = open(prefix + 'GT-'+ format(c, '05d') + '.csv') # annotations file\n",
    "        gtReader = csv.reader(gtFile, delimiter=';') # csv parser for annotations file\n",
    "        #gtReader.next() # skip header\n",
    "        # loop over all images in current annotations file\n",
    "        i=0\n",
    "        for row in gtReader:\n",
    "            if (i is not 0):\n",
    "                images.append(plt.imread(prefix + row[0])) # the 1th column is the filename\n",
    "                labels.append(row[7]) # the 8th column is the label\n",
    "            i+=1\n",
    "        gtFile.close()\n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_grayscale(img):\n",
    "    \"\"\"\n",
    "    Converts an image in RGB format to grayscale\n",
    "    \"\"\"\n",
    "    return cv.cvtColor(img, cv.COLOR_RGB2GRAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imageResize(img):\n",
    "    \n",
    "    width = 30\n",
    "    height = 30\n",
    "    dim = (width, height)\n",
    "\n",
    "    # resize image\n",
    "    resized = cv.resize(img, dim, interpolation=cv.INTER_AREA)\n",
    "    return (resized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fcn(rootpath):\n",
    "    \n",
    "    data, labels = readTrafficSigns(rootpath)\n",
    "    print(\"D\",len(data)) #39209\n",
    "    imgs=[]\n",
    "    for indx in range(0,len(data)):\n",
    "        # print(\"shimaa\",indx)\n",
    "        img=imageResize(data[indx])\n",
    "        img=to_grayscale(img)\n",
    "        imgs.append(img)\n",
    "    return imgs,labels \n",
    "   \n",
    "def createModel():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), padding='same', activation='relu', input_shape=(30,30,1)))\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    " \n",
    "    model.add(Conv2D(64, (3, 3), padding='same', activation='relu'))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    " \n",
    "    model.add(Conv2D(64, (3, 3), padding='same', activation='relu'))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    " \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(nClasses, activation='softmax'))\n",
    "     \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"start\")\n",
    "data,labels=fcn(\"GTSRB\\Final_Training\\Images\")\n",
    "#(trainX, testX, trainY, testY) = train_test_split(data,labels, test_size=0.1, random_state=42)\n",
    "print(\"reading data is donne\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array(data, dtype=\"float\") / 255.0\n",
    "labels = np.array(labels)\n",
    "data = data.reshape(data.shape[0], 30, 30 , 1).astype('float32')\n",
    "labels = np_utils.to_categorical(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Conv2D(40, kernel_size=5, padding=\"same\",input_shape=(28, 28, 1), activation = 'relu'))\n",
    "model.add(Conv2D(50, kernel_size=5, padding=\"valid\", activation = 'relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "model.add(Dropout(0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Conv2D(70, kernel_size=3, padding=\"same\", activation = 'relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "model.add(Conv2D(100, kernel_size=3, padding=\"valid\", activation = 'relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Flatten())\n",
    "model.add(Dense(100))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Dropout(0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense())\n",
    "model.add(Activation(\"softmax\"))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(data, labels, epochs= 32 , batch_size=200, validation_split = 0.2)\n",
    "# scores = model.evaluate(X_test, y_test, verbose = 10 )\n",
    "# print ( scores )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"done\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
