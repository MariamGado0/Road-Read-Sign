{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import math\n",
    "from Practice_2 import *\n",
    "import csv\n",
    "import queue\n",
    "#import pyttsx3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_times={}\n",
    "out_imgs ={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hsv_colorname(color):\n",
    "    # red = np.uint8([[[255,0,0 ]]])\n",
    "    # hsv_red = cv2.cvtColor(red,cv2.COLOR_BGR2HSV)\n",
    "    hsv_color={'blue':[[100,150,0],[140,255,255]],'red':[[170,50,50],[180,255,255],[0,50,50],[10,255,255]],\\\n",
    "               'white':[[0,0,255],[0,0,255],[0,0,255]],'black':[0, 0, 0]}\n",
    "    hsv = hsv_color[color]\n",
    "    return (np.array(hsv[0]),np.array(hsv[1]))\n",
    "    \n",
    "def BGR2HSV(img,color_names):\n",
    "    \n",
    "    hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "    i=0\n",
    "    for color in color_names:\n",
    "            \n",
    "        lower,upper =hsv_colorname(color)\n",
    "        \n",
    "        # Threshold the HSV image to get only blue colors\n",
    "        mask = cv2.inRange(hsv, lower, upper)\n",
    "\n",
    "        # Bitwise-AND mask and original image\n",
    "        res = cv2.bitwise_and(img,img, mask= mask)\n",
    "        \n",
    "        if i != 0:\n",
    "            final_img += res\n",
    "        else: \n",
    "            final_img = res\n",
    "        i +=1    \n",
    "    \n",
    "    median = cv2.medianBlur(final_img,5)\n",
    "    # cv2.namedWindow('output', cv2.WINDOW_NORMAL)\n",
    "    # cv2.imshow(\"output\",np.hstack([median,img]))\n",
    "    # cv2.waitKey(0)\n",
    "    # cv2.destroyAllWindows()\n",
    "    return median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_preprocessing(img):\n",
    "    # img = cv2.medianBlur(frame, 5)\n",
    "    hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "    mask1 = cv2.inRange(hsv, np.array([0, 100, 100]), np.array([10, 255, 255]))  # lower red\n",
    "    mask2 = cv2.inRange(hsv, np.array([160, 100, 100]), np.array([230, 255, 255]))  # upper red 179\n",
    "    mask3 = cv2.inRange(hsv, np.array([100, 150, 0]), np.array([140, 255, 255]))  # upper blue\n",
    "    mask = mask1 + mask2 + mask3\n",
    "    # mask = cv2.max(mask1, mask2)\n",
    "    img = cv2.bitwise_and(img, img, mask=mask)\n",
    "    # img = cv2.medianBlur(img, 5)\n",
    "    kernel = np.ones((5, 5), np.float32) / 15\n",
    "    img = cv2.filter2D(img, -1, kernel)\n",
    "    img = cv2.medianBlur(img, 5)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using hough cicrle\n",
    "def cicles_detection(image,original_img):\n",
    "  \n",
    "    output = image.copy()\n",
    "    \n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    cir_list=[]\n",
    "    # detect circles in the image\n",
    "    #circles = cv2.HoughCircles(gray, cv2.HOUGH_GRADIENT, 3,300)   #3,300\n",
    "    circles = cv2.HoughCircles(gray, cv2.HOUGH_GRADIENT, 3, 300)\n",
    "    if circles  is not None:\n",
    "        \n",
    "        circles = np.round(circles[0,:]).astype(\"int\")\n",
    "        \n",
    "        for (x,y,r) in circles:\n",
    "            \n",
    "            if   r<=50:\n",
    "                cir_list.append((x,y,r))\n",
    "                cv2.circle(output,(x,y),r,(0,255,0),4)\n",
    "                cv2.rectangle(output,(x-5,y-5),(x+5,y+5),(0,128,255),-1) \n",
    "                cv2.circle(original_img,(x,y),r,(0,255,0),4)\n",
    "                cv2.rectangle(original_img,(x-5,y-5),(x+5,y+5),(0,128,255),-1)  \n",
    "        \n",
    "    return output,original_img,cir_list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using contoure detection \n",
    "def rectangle_detection(img,original_img):\n",
    "    \n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    #ret,thresh = cv2.threshold(gray,127,255,1)\n",
    "   \n",
    "    gray = cv2.GaussianBlur(gray, (3, 3), 0)\n",
    "    edged = cv2.Canny(gray, 10, 250)\n",
    "   \n",
    "    rec_list=[]\n",
    "    _,contours,_ = cv2.findContours(edged,cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    for cnt in contours:\n",
    "        approx = cv2.approxPolyDP(cnt,0.01*cv2.arcLength(cnt,True),True)\n",
    "        area = cv2.contourArea(cnt)\n",
    "        if area <=200 :\n",
    "            continue \n",
    "        hull = cv2.convexHull(cnt,returnPoints = True)\n",
    "        \n",
    "        if len(approx)==3:\n",
    "            print (\"triangle area\",area)\n",
    "            cv2.drawContours(img,[cnt],-1,(0,128,255),4)\n",
    "            cv2.drawContours(original_img,[cnt],-1,(0,128,255),4)\n",
    "        elif len(approx)==4:\n",
    "            leftmost = tuple(cnt[cnt[:,:,0].argmin()][0])\n",
    "            rightmost = tuple(cnt[cnt[:,:,0].argmax()][0])\n",
    "            topmost = tuple(cnt[cnt[:,:,1].argmin()][0])\n",
    "            bottommost = tuple(cnt[cnt[:,:,1].argmax()][0])\n",
    "            print(len(hull),\"shimaa\",leftmost,rightmost,topmost,bottommost)\n",
    "            print (\"square area\",area )\n",
    "            M = cv2.moments(cnt)\n",
    "            rec_list.append([M['m10']/M['m00'],M['m01']/M['m00']])\n",
    "            cv2.drawContours(img,[cnt],-1,(0,128,255),4)\n",
    "            cv2.drawContours(original_img,[cnt],-1,(0,128,255),4)\n",
    "    \n",
    "    return img,original_img,rec_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for triangle\n",
    "def template_matching(img,frame):\n",
    "    rectangle_center=[]\n",
    "    img2 = img.copy()\n",
    "    img= cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    template = cv2.imread('triangle_S2.png',0) # 1.jpg\n",
    "    #template =cv2.cvtColor(tmp, cv2.COLOR_BGR2GRAY)\n",
    "    #template = cv2.resize(template,img.shape[0:2])\n",
    "    template=cv2.resize(template,(50, 50))  #triangle\n",
    "    # cv2.imshow(\"tmp\",template)\n",
    "    # cv2.waitKey(0)\n",
    "    #template=cv2.resize(template,(50, 70))  #rectangle\n",
    "    w, h = template.shape[::-1]\n",
    "    #All the 6 methods for comparison in a list\n",
    "    methods = [#'cv2.TM_CCOEFF', 'cv2.TM_CCOEFF_NORMED', 'cv2.TM_CCORR',\n",
    "                'cv2.TM_CCOEFF_NORMED','cv2.TM_CCORR_NORMED']#, 'cv2.TM_SQDIFF', 'cv2.TM_SQDIFF_NORMED']\n",
    "    for meth in methods:\n",
    "        method = eval(meth)\n",
    "        # Apply template Matching\n",
    "        res = cv2.matchTemplate(img,template,method)\n",
    "        min_val, max_val, min_loc, max_loc = cv2.minMaxLoc(res)\n",
    "        # If the method is TM_SQDIFF or TM_SQDIFF_NORMED, take minimum\n",
    "        if method in [cv2.TM_SQDIFF, cv2.TM_SQDIFF_NORMED]:\n",
    "            top_left = min_loc\n",
    "        else:\n",
    "            top_left = max_loc\n",
    "        if max_val > 0.7 :\n",
    "            print(max_val)\n",
    "            rectangle_center.append((top_left[0] + 0.5*w, top_left[1] + 0.5*h))\n",
    "            bottom_right = (top_left[0] + w, top_left[1] + h)\n",
    "            cv2.rectangle(img2,top_left, bottom_right, 255, 2)\n",
    "            cv2.rectangle(frame, top_left, bottom_right, 255, 2)\n",
    "        # cv2.imshow('d',img)\n",
    "        # cv2.waitKey(0)\n",
    "    return img2,frame,rectangle_center"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def invlidate_circles(rec_l,cir_l,frame):\n",
    "    for x1,y1 in rec_l:\n",
    "        for x2,y2,_ in cir_l:\n",
    "            dist = math.sqrt( (x2 - x1)**2 + (y2 - y1)**2 )\n",
    "            print(\"dis\",dist)\n",
    "            if dist > 90 :\n",
    "                cv2.circle(frame,(x,y),r,(0,255,0),4)\n",
    "    return frame        \n",
    "            \n",
    "def invalid_drawing(rec_l,cir_l,triangle,frame):\n",
    "    checl_circl = []\n",
    "    if len(rec_l) == 0 and len(triangle) == 0 and len(cir_l) != 0:\n",
    "        for x,y,r in cir_l:\n",
    "            cv2.circle(frame, (x, y), r, (0, 255, 0), 4)\n",
    "            cv2.rectangle(frame, (x - 5, y - 5), (x + 5, y + 5), (0, 128, 255), -1)\n",
    "        return -1,frame\n",
    "    elif len(rec_l)==0 and len(cir_l)!=0 and len(triangle) ==1 :\n",
    "        print(\"yes\")\n",
    "        (x2,y2) = triangle[0]\n",
    "        for i in range(0, len(cir_l)):\n",
    "            x1,y1,_ = cir_l[i]\n",
    "            dist = math.sqrt((x2 - x1) ** 2 + (y2 - y1) ** 2)\n",
    "            print(\"dis\", dist)\n",
    "            if dist > 90 :\n",
    "                checl_circl.append(cir_l[i])\n",
    "        return 0,checl_circl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_label(sign):\n",
    "    return 1,80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_convert():\n",
    "    with open('signnames.csv') as f:\n",
    "        out_labels = f.readlines()\n",
    "    f.close()\n",
    "    return  out_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_out_img():\n",
    "    nxt_frame = cv2.imread(\"black_6.jpg\", 1)\n",
    "    nxt_frame = cv2.resize(nxt_frame, (900, 800))\n",
    "    o = cv2.imread(\"black_10.png\",1)\n",
    "    o = cv2.resize(o, (580, 580))\n",
    "    nxt_frame[85:665, 25:605] = o[:, :]\n",
    "    cv2.rectangle(nxt_frame, (613, 85), (860, 715), (255, 255, 255), -1)\n",
    "    textt = \"Traffic Sign \"\n",
    "    cv2.putText(nxt_frame, textt, (650, 70), cv2.FONT_HERSHEY_SIMPLEX, 1.0, (200, 255, 255), 2,\n",
    "                lineType=cv2.LINE_AA)\n",
    "    g11 = cv2.imread(\"g11.png\", 1)\n",
    "    g11 = cv2.resize(g11, (200, 50))  # w,h\n",
    "    nxt_frame[665:715, 25:225] = g11[:, :]\n",
    "    g22 = cv2.imread(\"g22.png\", 1)\n",
    "    g22 = cv2.resize(g22, (200, 50))\n",
    "    nxt_frame[665:715, 225:425] = g22[:, :]\n",
    "    g33 = cv2.imread(\"g33.png\", 1)\n",
    "    g33 = cv2.resize(g33, (180, 50))\n",
    "    nxt_frame[665:715, 425:605] = g33[:, :]\n",
    "    return  nxt_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def voice_word():\n",
    "    engine = pyttsx3.init()\n",
    "    mm = 'Welcome'\n",
    "    volume = engine.getProperty('volume')\n",
    "    voices = engine.getProperty('voices')\n",
    "    rate = engine.getProperty('rate')\n",
    "    engine.setProperty('rate', rate - 50)\n",
    "    engine.setProperty('voice', voices[1].id)  # 0 is man , 1 is woman\n",
    "    engine.setProperty('volume', volume + 2000)\n",
    "    #return  engine\n",
    "    for i in range(0, 3):\n",
    "        engine.say(mm)\n",
    "    engine.runAndWait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recognition_2(cir_l,out_frame,nxt_frame):\n",
    "    global count_times,out_imgs\n",
    "    size = 120\n",
    "    sp_x, sp_y = 615, 87\n",
    "    l=[]\n",
    "    for key, value in count_times.items():\n",
    "        if value == 10:\n",
    "            l.append(key)\n",
    "        else:\n",
    "            count_times[key] +=1\n",
    "            nxt_frame[sp_y:sp_y + size, sp_x:sp_x + size] = out_imgs[key][0][:,:]\n",
    "            textt = out_imgs[key][1]\n",
    "            cv2.putText(nxt_frame, textt, (sp_x, sp_y + size + 15), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 1,\n",
    "                        lineType=cv2.LINE_AA)\n",
    "            sp_y += size + 20\n",
    "    for key in l:\n",
    "        del count_times[key]\n",
    "        del out_imgs[key]\n",
    "    for x, y, r in cir_l:\n",
    "        sign = out_frame[y - r - 2:y + r + 2, x - r - 2:x + r + 2].copy()\n",
    "        try:\n",
    "            sign2 = cv2.resize(sign, (50, 50))\n",
    "        except:\n",
    "            print(\"false\")\n",
    "            continue\n",
    "        sign_label, prob = cnn_label(sign)\n",
    "        if prob > 70:\n",
    "            cv2.rectangle(out_frame, (x - r, y - r), (x + r, y + r), (0, 128, 255), 3)\n",
    "            if sign_label in count_times:\n",
    "                count_times[sign_label]=0\n",
    "                continue\n",
    "            sign = cv2.resize(sign, (size, size))\n",
    "            nxt_frame[sp_y:sp_y+size, sp_x:sp_x+size] = sign[:, :]\n",
    "            textt = out_labels[sign_label + 1].split(',')[1]\n",
    "            cv2.putText(nxt_frame, textt, (sp_x, sp_y+size+15), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 1,\n",
    "                        lineType=cv2.LINE_AA)\n",
    "            sp_y += size + 20\n",
    "            count_times[sign_label] = 0\n",
    "            out_imgs[sign_label] = [sign,textt]\n",
    "    o = cv2.resize(out_frame, (580, 580))\n",
    "    nxt_frame[85:665, 25:605] = o[:, :]\n",
    "    return out_frame, nxt_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recognition(cir_l,rec_l,out_frame):\n",
    "    nxt_frame = cv2.imread(\"black.jpg\",1)\n",
    "    nxt_frame = cv2.resize(nxt_frame,(out_frame.shape[1],out_frame.shape[0]))\n",
    "    count =0\n",
    "    size = 120\n",
    "    for x,y,r in cir_l:\n",
    "        sign = out_frame[y-r-2:y+r+2,x-r-2:x+r+2].copy()\n",
    "        try:\n",
    "            sign2 = cv2.resize(sign,(50,50))\n",
    "            # cv2.imshow(\"hagur\",sign)\n",
    "            # cv2.waitKey(0)\n",
    "        except :\n",
    "            print(\"false\")\n",
    "            continue\n",
    "        count +=1\n",
    "        sign_label,prob=cnn_label(sign)\n",
    "        if prob > 70:\n",
    "            print(\"yes\")\n",
    "            cv2.circle(out_frame, (x, y), r, (0, 255, 0), 4)\n",
    "            cv2.rectangle(out_frame, (x - 5, y - 5), (x + 5, y + 5), (0, 128, 255), -1)\n",
    "            sign =cv2.resize(sign,(size,size))\n",
    "            str= size*(count-1)\n",
    "            end = size*count\n",
    "            nxt_frame[str:end,str:end] =  sign[:,:]\n",
    "            textt = out_labels[sign_label +1].split(',')[1]\n",
    "            cv2.putText(nxt_frame, textt, (end, end), cv2.FONT_HERSHEY_SIMPLEX, 1.0, (0, 255, 0),2 ,lineType=cv2.LINE_AA)\n",
    "            # cv2.imshow(\"shimaa\", nxt_frame)\n",
    "            # cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    return  out_frame,nxt_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_gamma(image, gamma=1.0):\n",
    "    # build a lookup table mapping the pixel values [0, 255] to\n",
    "    # their adjusted gamma values\n",
    "    invGamma = 1.0 / gamma\n",
    "    table = np.array([((i / 255.0) ** invGamma) * 255\n",
    "                      for i in np.arange(0, 256)]).astype(\"uint8\")\n",
    "\n",
    "    # apply gamma correction using the lookup table\n",
    "    return cv2.LUT(image, table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_prightness(original):\n",
    "    # loop over various values of gamma\n",
    "    for gamma in [1.5]:\n",
    "        # ignore when gamma is 1 (there will be no change to the image)\n",
    "        if gamma == 1:\n",
    "            continue\n",
    "\n",
    "        # apply gamma correction and show the images\n",
    "        gamma = gamma if gamma > 0 else 0.1\n",
    "        adjusted = adjust_gamma(original, gamma=gamma)\n",
    "        cv2.putText(adjusted, \"g={}\".format(gamma), (10, 30),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 255), 3)\n",
    "        cv2.imshow(\"Images\", np.hstack([original, adjusted]))\n",
    "        cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(\"v2.mp4\") #v2.mp4 ,1280,720\n",
    "# Define the codec and create VideoWriter object\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "out = cv2.VideoWriter('tested.avi',fourcc, 20.0,(1280,720) ,1)\n",
    "out_labels = label_convert()\n",
    "tmp_img =prepare_out_img()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# out.write(tmp_img)\n",
    "# out.write(tmp_img)\n",
    "# out.write(tmp_img)\n",
    "# cv2.namedWindow('hagur', cv2.WINDOW_NORMAL)\n",
    "# cv2.imshow(\"hagur\",tmp_img)\n",
    "# cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while(cap.isOpened()):\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    if ret==True:\n",
    "\n",
    "\n",
    "        out_frame =  frame.copy()\n",
    "        img = img_preprocessing(frame)\n",
    "\n",
    "        img,frame,cir_l = cicles_detection(img,frame)\n",
    "        img,frame,rec_l = rectangle_detection(img,frame)\n",
    "\n",
    "        #out_frame,nxt = recognition(cir_l,rec_l,out_frame)\n",
    "        out_frame, nxt = recognition_2(cir_l,out_frame,tmp_img.copy()) #.copy()\n",
    "\n",
    "        #out.write(np.hstack([out_frame,nxt]))\n",
    "        print(nxt.shape)\n",
    "        out.write(nxt)\n",
    "        cv2.namedWindow('output', cv2.WINDOW_NORMAL)\n",
    "        cv2.imshow(\"output\",nxt)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Release everything if job is finished\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
